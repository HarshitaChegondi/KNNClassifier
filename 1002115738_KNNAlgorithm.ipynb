{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd02670",
   "metadata": {},
   "source": [
    "# PreProcess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae9663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "hrLink = 'HayesRoth/hayes-roth.data'\n",
    "\n",
    "hrDF = pd.read_csv(hrLink, header=None)\n",
    "hrDF = hrDF.apply(LabelEncoder().fit_transform)\n",
    "hrFeatures = hrDF.iloc[:, :-1].values.tolist()\n",
    "hrLabels = hrDF.iloc[:, -1].tolist()\n",
    "\n",
    "\n",
    "hrTestLink = 'HayesRoth/hayes-roth.test'\n",
    "\n",
    "hrDFTest = pd.read_csv(hrLink, header=None)\n",
    "hrDFTest = hrDFTest.apply(LabelEncoder().fit_transform)\n",
    "hrTestFeatures = hrDFTest.iloc[:, :-1].values.tolist()\n",
    "hrTestLabels = hrDF.iloc[:, -1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3110812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "carLink = 'CarEvaluation/car.data'\n",
    "\n",
    "carDF = pd.read_csv(carLink, header=None)\n",
    "carDF = carDF.apply(LabelEncoder().fit_transform)\n",
    "carFeatures = carDF.iloc[:, :-1].values.tolist()\n",
    "carLabels = carDF.iloc[:, -1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c00be112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cancerLink = 'BreastCancer/breast-cancer.data'\n",
    "\n",
    "cancerDF = pd.read_csv(cancerLink, header=None)\n",
    "cancerDF = cancerDF.apply(LabelEncoder().fit_transform)\n",
    "cancerFeatures = cancerDF.iloc[:, :-1].values.tolist()\n",
    "cancerLabels = cancerDF.iloc[:, -1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a737092",
   "metadata": {},
   "source": [
    "# KNN without SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "230ba51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from heapq import nsmallest\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class KNNClassifier:\n",
    "    \n",
    "    def __init__(self, k=7, dis_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.dis_metric = dis_metric\n",
    "        self.train_data = []\n",
    "        self.train_labels = []\n",
    "    \n",
    "\n",
    "    def train(self, train_data, train_labels):\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "    def euclidean_distance(self, v1, v2):\n",
    "        if len(v1) != len(v2):\n",
    "            raise ValueError(\"Undefined for sequences of unequal length.\")\n",
    "        return sum((a - b) ** 2 for a, b in zip(v1, v2)) ** 0.5\n",
    "\n",
    "\n",
    "    def get_neighbors(self, test_row):\n",
    "        dis_metrics = {\n",
    "            'euclidean': self.euclidean_distance,\n",
    "        }\n",
    "        if self.dis_metric not in dis_metrics:\n",
    "            raise ValueError(\"Invalid distance metric\")\n",
    "        calc_distance = dis_metrics[self.dis_metric]\n",
    "        distances = [\n",
    "            (train_row, calc_distance(test_row, train_row), label)\n",
    "            for train_row, label in zip(self.train_data, self.train_labels)\n",
    "        ]\n",
    "        k_nearest = nsmallest(self.k, distances, key=lambda x: x[1])\n",
    "        return k_nearest\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        predictions = []\n",
    "        for test_case in x_test:\n",
    "            neighbors = self.get_neighbors(test_case)\n",
    "            output = [row[-1] for row in neighbors]\n",
    "            prediction = Counter(output).most_common(1)[0][0]\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a26f2",
   "metadata": {},
   "source": [
    "# KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a946b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kFoldCV:\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier  \n",
    "    \n",
    "    def cross_val_split(self, dataset, num_folds):\n",
    "        data_split = []\n",
    "        data_copy = list(dataset)\n",
    "        fold_size = len(dataset) // num_folds\n",
    "        for _ in range(num_folds):\n",
    "            if fold_size <= len(data_copy):\n",
    "                fold = random.sample(data_copy, fold_size)\n",
    "            else:\n",
    "                fold = data_copy  # If the fold size is larger than the remaining data, use all the data\n",
    "            data_split.append(fold)\n",
    "            data_copy = [row for row in data_copy if row not in fold]\n",
    "        return data_split\n",
    "\n",
    "    def k_foldEvaluate(self, dataset, num_folds):\n",
    "        folds = self.cross_val_split(dataset, num_folds)\n",
    "        scores = []\n",
    "        \n",
    "\n",
    "        for fold_number, fold in enumerate(folds, 1):\n",
    "            train_set = [row for row in dataset if row not in fold]\n",
    "            test_set = [row for row in fold]\n",
    "            train_labels, train_set = zip(*[(row[-1], row[:-1]) for row in train_set])\n",
    "            test_labels, test_set = zip(*[(row[-1], row[:-1]) for row in test_set])\n",
    "            self.classifier.train(train_set, train_labels)\n",
    "            predicted = self.classifier.predict(test_set)\n",
    "            accuracy = self.calculate_accuracy(test_labels, predicted)\n",
    "            finalAccuracy = round(accuracy, 2)\n",
    "            scores.append(finalAccuracy)\n",
    "        \n",
    "            print(f\"Fold {fold_number}: Accuracy = {finalAccuracy}%\")\n",
    "            \n",
    "        return scores\n",
    "\n",
    "       \n",
    "    def calculate_accuracy(self, actual, predicted):\n",
    "        assert len(actual) == len(predicted)\n",
    "        correct = sum(1 for a, p in zip(actual, predicted) if a == p)\n",
    "        return (correct / len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b557bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(actual, predictions):\n",
    "    if actual is None or predictions is None:\n",
    "        print(\"Error: Both 'actual' and 'predictions' must be valid lists.\")\n",
    "        return\n",
    "    \n",
    "    assert len(actual) == len(predictions)\n",
    "    correct = sum(1 for a, p in zip(actual, predictions) if a == p)\n",
    "    accuracy = (correct / len(actual)) * 100.0\n",
    "    print(\"Accuracy of kNN model: {:.2f}%\".format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8707a5",
   "metadata": {},
   "source": [
    "# Packages used for this KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c9f7cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a424eba",
   "metadata": {},
   "source": [
    "# Hayes Roth Dataset Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "86fa5b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of kNN model: 22.22%\n",
      "Fold 1: Accuracy = 38.46%\n",
      "Fold 2: Accuracy = 38.46%\n",
      "Fold 3: Accuracy = 61.54%\n",
      "Fold 4: Accuracy = 53.85%\n",
      "Fold 5: Accuracy = 15.38%\n",
      "Fold 6: Accuracy = 38.46%\n",
      "Fold 7: Accuracy = 30.77%\n",
      "Fold 8: Accuracy = 46.15%\n",
      "Fold 9: Accuracy = 46.15%\n",
      "Fold 10: Accuracy = 38.46%\n",
      "Accuracy of kNN model using SKlearn: 48.15%\n",
      "Fold 1: Accuracy = 14.29%\n",
      "Fold 2: Accuracy = 50.00%\n",
      "Fold 3: Accuracy = 61.54%\n",
      "Fold 4: Accuracy = 53.85%\n",
      "Fold 5: Accuracy = 30.77%\n",
      "Fold 6: Accuracy = 46.15%\n",
      "Fold 7: Accuracy = 76.92%\n",
      "Fold 8: Accuracy = 53.85%\n",
      "Fold 9: Accuracy = 46.15%\n",
      "Fold 10: Accuracy = 69.23%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hrFeatures, hrLabels, test_size=0.2)\n",
    "knn = KNNClassifier()\n",
    "knn.train(X_train, y_train)\n",
    "hr_euc_pred = knn.predict(X_test)\n",
    "nosklearnAccuracyHR = print_metrics(y_test, hr_euc_pred)\n",
    "kfcv = kFoldCV(knn)\n",
    "KFoldNoSkl = kfcv.k_foldEvaluate(hrTestFeatures, 10)\n",
    " \n",
    "# SKlearn\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "k = 3  # Number of neighbors\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "sk_accuracy_HR = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of kNN model using SKlearn: {sk_accuracy_HR * 100:.2f}%\")\n",
    "\n",
    "X = np.vstack((X_train, X_test))\n",
    "y = np.hstack((y_train, y_test))\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(knn_classifier, X, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "hrarray = []\n",
    "for i, score in enumerate(cv_scores):\n",
    "    print(f\"Fold {i + 1}: Accuracy = {score * 100:.2f}%\")\n",
    "    hrarray.append(round(score*100,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "61e1ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.46, 38.46, 61.54, 53.85, 15.38, 38.46, 30.77, 46.15, 46.15, 38.46]\n",
      "[14.29, 50.0, 61.54, 53.85, 30.77, 46.15, 76.92, 53.85, 46.15, 69.23]\n",
      "-1.3662927000951348\n",
      "0.18867435817517453\n",
      "No significant difference between KNN and SKLearn-KNN Accuracies.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Sample data for two groups\n",
    "normalKNN = KFoldNoSkl\n",
    "sklearnKNN = hrarray\n",
    "print(normalKNN)\n",
    "print(sklearnKNN)\n",
    "# Perform the independent samples t-test\n",
    "t_stat, p_value = stats.ttest_ind(normalKNN, sklearnKNN)\n",
    "\n",
    "print(t_stat)\n",
    "print(p_value)\n",
    "\n",
    "# Check the p-value to determine significance\n",
    "if p_value < 0.05:  # 0.05 is a common significance level\n",
    "    print(\"A notable significant difference exists between KNN and SKLearn-KNN Accuracies.\")\n",
    "else:\n",
    "    print(\"No significant difference between KNN and SKLearn-KNN Accuracies.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34cbd56",
   "metadata": {},
   "source": [
    "# Car Evaluation Dataset Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a1e37082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of kNN model: 92.20%\n",
      "Fold 1: Accuracy = 3.49%\n",
      "Fold 2: Accuracy = 1.74%\n",
      "Fold 3: Accuracy = 2.91%\n",
      "Fold 4: Accuracy = 2.33%\n",
      "Fold 5: Accuracy = 1.16%\n",
      "Fold 6: Accuracy = 2.33%\n",
      "Fold 7: Accuracy = 2.33%\n",
      "Fold 8: Accuracy = 1.74%\n",
      "Fold 9: Accuracy = 1.74%\n",
      "Fold 10: Accuracy = 3.49%\n",
      "Accuracy of kNN model using SKlearn: 93.06%\n",
      "Fold 1: Accuracy = 93.64%\n",
      "Fold 2: Accuracy = 93.06%\n",
      "Fold 3: Accuracy = 95.38%\n",
      "Fold 4: Accuracy = 92.49%\n",
      "Fold 5: Accuracy = 95.95%\n",
      "Fold 6: Accuracy = 96.53%\n",
      "Fold 7: Accuracy = 89.60%\n",
      "Fold 8: Accuracy = 89.60%\n",
      "Fold 9: Accuracy = 91.28%\n",
      "Fold 10: Accuracy = 93.60%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(carFeatures, carLabels, test_size=0.2)\n",
    "knn = KNNClassifier()\n",
    "knn.train(X_train, y_train)\n",
    "car_euc_pred = knn.predict(X_test)\n",
    "nosklearnAccuracyCar = print_metrics(y_test, car_euc_pred)\n",
    "kfcv = kFoldCV(knn)\n",
    "ceNoSKLArray = kfcv.k_foldEvaluate(carFeatures, 10)\n",
    "\n",
    "\n",
    "# SKlearn\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "k = 3  # Number of neighbors\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "sk_accuracy_Car = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of kNN model using SKlearn: {sk_accuracy_Car * 100:.2f}%\")\n",
    "\n",
    "\n",
    "X = np.vstack((X_train, X_test))\n",
    "y = np.hstack((y_train, y_test))\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(knn_classifier, X, y, cv=kfold, scoring='accuracy')\n",
    "cearray = []\n",
    "for i, score in enumerate(cv_scores):\n",
    "    print(f\"Fold {i + 1}: Accuracy = {score * 100:.2f}%\")\n",
    "    cearray.append(round(score*100,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "42a5097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.49, 1.74, 2.91, 2.33, 1.16, 2.33, 2.33, 1.74, 1.74, 3.49]\n",
      "[93.64, 93.06, 95.38, 92.49, 95.95, 96.53, 89.6, 89.6, 91.28, 93.6]\n",
      "-111.89012623558473\n",
      "4.809953730856732e-27\n",
      "A notable significant difference exists between KNN and SKLearn-KNN Accuracies.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Sample data for two groups\n",
    "normalKNN = ceNoSKLArray\n",
    "sklearnKNN = cearray\n",
    "print(normalKNN)\n",
    "print(sklearnKNN)\n",
    "\n",
    "# Perform the independent samples t-test\n",
    "t_stat, p_value = stats.ttest_ind(normalKNN, sklearnKNN)\n",
    "\n",
    "print(t_stat)\n",
    "print(p_value)\n",
    "\n",
    "# Check the p-value to determine significance\n",
    "if p_value < 0.05:  # 0.05 is a common significance level\n",
    "    print(\"A notable significant difference exists between KNN and SKLearn-KNN Accuracies.\")\n",
    "else:\n",
    "    print(\"No significant difference between KNN and SKLearn-KNN Accuracies.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bed50",
   "metadata": {},
   "source": [
    "# Breast Cancer Dataset Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ddbd5c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of kNN model: 79.31%\n",
      "Fold 1: Accuracy = 17.86%\n",
      "Fold 2: Accuracy = 32.14%\n",
      "Fold 3: Accuracy = 17.86%\n",
      "Fold 4: Accuracy = 32.14%\n",
      "Fold 5: Accuracy = 32.14%\n",
      "Fold 6: Accuracy = 39.29%\n",
      "Fold 7: Accuracy = 32.14%\n",
      "Fold 8: Accuracy = 25.0%\n",
      "Fold 9: Accuracy = 25.0%\n",
      "Fold 10: Accuracy = 25.0%\n",
      "Accuracy of kNN model using SKlearn: 77.59%\n",
      "Fold 1: Accuracy = 75.86%\n",
      "Fold 2: Accuracy = 72.41%\n",
      "Fold 3: Accuracy = 86.21%\n",
      "Fold 4: Accuracy = 68.97%\n",
      "Fold 5: Accuracy = 75.86%\n",
      "Fold 6: Accuracy = 72.41%\n",
      "Fold 7: Accuracy = 71.43%\n",
      "Fold 8: Accuracy = 75.00%\n",
      "Fold 9: Accuracy = 71.43%\n",
      "Fold 10: Accuracy = 71.43%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancerFeatures, cancerLabels, test_size=0.2)\n",
    "knn = KNNClassifier()\n",
    "knn.train(X_train, y_train)\n",
    "cancer_euc_pred = knn.predict(X_test)\n",
    "nosklearnAccuracyCancer = print_metrics(y_test, cancer_euc_pred)\n",
    "kfcv = kFoldCV(knn)\n",
    "bcnoSKLarray = kfcv.k_foldEvaluate(cancerFeatures, 10)\n",
    "\n",
    "# SKlearn\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "k = 3  # Number of neighbors\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "sk_accuracy_Cancer = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of kNN model using SKlearn: {sk_accuracy_Cancer * 100:.2f}%\")\n",
    "\n",
    "\n",
    "X = np.vstack((X_train, X_test))\n",
    "y = np.hstack((y_train, y_test))\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(knn_classifier, X, y, cv=kfold, scoring='accuracy')\n",
    "bcarray = []\n",
    "for i, score in enumerate(cv_scores):\n",
    "    print(f\"Fold {i + 1}: Accuracy = {score * 100:.2f}%\")\n",
    "    bcarray.append(round(score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "15396651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.86, 32.14, 17.86, 32.14, 32.14, 39.29, 32.14, 25.0, 25.0, 25.0]\n",
      "[75.86, 72.41, 86.21, 68.97, 75.86, 72.41, 71.43, 75.0, 71.43, 71.43]\n",
      "-17.40237474899569\n",
      "1.0479826208634378e-12\n",
      "A notable significant difference exists between KNN and SKLearn-KNN Accuracies.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Sample data for two groups\n",
    "normalKNN = bcnoSKLarray\n",
    "sklearnKNN = bcarray\n",
    "\n",
    "print(normalKNN)\n",
    "print(sklearnKNN)\n",
    "\n",
    "# Perform the independent samples t-test\n",
    "t_stat, p_value = stats.ttest_ind(normalKNN, sklearnKNN)\n",
    "\n",
    "print(t_stat)\n",
    "print(p_value)\n",
    "\n",
    "# Check the p-value to determine significance\n",
    "if p_value < 0.05:  # 0.05 is a common significance level\n",
    "    print(\"A notable significant difference exists between KNN and SKLearn-KNN Accuracies.\")\n",
    "else:\n",
    "    print(\"No significant difference  between KNN and SKLearn-KNN Accuracies.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c451e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
